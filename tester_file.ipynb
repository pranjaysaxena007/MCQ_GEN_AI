{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c6cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from src.mcqgenerator.utils import read_file,get_table_data\n",
    "from src.mcqgenerator.looger import logging\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    google_api_key = os.getenv(\"GOOGLE-API-KEY\"),\n",
    "    temperature = 0.7,\n",
    ")\n",
    "\n",
    "quiz_generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"You are an expert MCQ quiz maker. You have to create the quiz based on user input and given instructions.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content = \"\"\"\n",
    "                Please create {number} muliple choice questions in a {tone} tone based on the following text.\n",
    "                **Text:**\n",
    "                {text}\n",
    "                \n",
    "                **Instructions:**\n",
    "                1. Ensure that all questions are from given text only.\n",
    "                2. Ensure that the questions are not repeated.\n",
    "                3. Format your entire response as a JSON object that strictly follows below given scheme.\n",
    "                {response_json}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]    \n",
    ")\n",
    "\n",
    "quiz_chain = quiz_generation_prompt | llm | StrOutputParser()\n",
    "\n",
    "review_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content =\"You are an expert MCQ Analyzer for student benefit. You have to evaluate the given quiz as per instructions given below\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"\"\"Please review the multiple choice quiz intendede for {subject} sy=tudents.\n",
    "                **Quiz for review:**\n",
    "                '''json\n",
    "                {quiz}\n",
    "                '''\n",
    "\n",
    "                **Your Task:**\n",
    "                1. Evaluate the compleity of the questions.\n",
    "                2. Assess if the quiz is appropriate for students cognitive and quantitative ability.\n",
    "                3. New questions and answers created must be from given text only. The text is:{text}\n",
    "                4. If the quiz is not suitable, then rewrite the questions and adjust the tone to perfectly fit students abilities.\n",
    "                5. Provide a brief analysis of your changes or your approval of the original quiz.\n",
    "                \n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "review_chain = review_prompt | llm | StrOutputParser()\n",
    "\n",
    "genereate_evaluate_chain =(\n",
    "    RunnablePassthrough.assign(quiz = quiz_chain) | \n",
    "    RunnablePassthrough.assign(review = review_chain)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "302fe1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from src.mcqgenerator.utils import read_file\n",
    "from src.mcqgenerator.MCQGenerator import genereate_evaluate_chain\n",
    "from src.mcqgenerator.looger import logging\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "with open('Response.json','r') as file:\n",
    "    RESPONSE_JSON = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62d0e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_28044\\3794405900.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  file_path = \"P:\\Code\\Gen_AI_course_ineuron\\MCQ_GEN_AI\\data.txt\"\n"
     ]
    }
   ],
   "source": [
    "file_path = \"P:\\Code\\Gen_AI_course_ineuron\\MCQ_GEN_AI\\data.txt\"\n",
    "with open(file_path,\"r\") as file:\n",
    "    TEXT = file.read()\n",
    "uploaded_file = TEXT\n",
    "mcq_count = 5\n",
    "subject = \"Machine Learning\"\n",
    "tone= \"Simple\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "555e58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "                response = genereate_evaluate_chain.invoke(\n",
    "                    {\n",
    "                        \"text\": TEXT,\n",
    "                        \"number\":mcq_count,\n",
    "                        \"subject\": subject,\n",
    "                        \"tone\":tone,\n",
    "                        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b9523e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The Dawn of a New Intelligence: An In-Depth Exploration of Machine Learning\\nIntroduction: The Silent Revolution\\nIn the 21st century, a quiet but profound revolution is reshaping our world. It operates behind the screens of our devices, influences the products we buy, powers the entertainment we consume, and even helps doctors diagnose diseases. This revolution is driven by Machine Learning (ML), a powerful branch of artificial intelligence (AI) that, at its core, is about teaching computers to learn from data without being explicitly programmed for every task.\\n\\nFor centuries, human intelligence was the sole driver of innovation and problem-solving. We built machines to automate physical labor, following precise, human-written instructions. A calculator, for instance, performs complex arithmetic, but it only does what its programming dictates. It cannot learn, adapt, or discover a new mathematical theorem on its own. Machine learning shatters this paradigm. Instead of providing the computer with a set of rigid rules, we provide it with data and an objective, and it learns the rules for itself.\\n\\nThe recent explosion of machine learning can be attributed to a perfect storm of three key factors:\\n\\nThe Data Deluge: The digital age has created an unfathomable amount of data. Every click, search, purchase, and social media interaction generates data points. This massive repository of information is the lifeblood of ML algorithms, providing the raw material from which they can learn.\\n\\nComputational Power: Moore\\'s Law, the observation that the number of transistors on a microchip doubles about every two years, has held steady for decades. The development of specialized hardware, particularly Graphics Processing Units (GPUs), has provided the immense computational horsepower needed to process vast datasets and train complex models.\\n\\nAlgorithmic Advancements: Researchers have developed increasingly sophisticated algorithms and neural network architectures, allowing models to tackle problems of unprecedented complexity, from understanding human language to identifying cancerous cells in medical scans.\\n\\nIt\\'s important to distinguish machine learning from its related fields. Artificial Intelligence (AI) is the broader concept of creating machines that can simulate human intelligence. Machine Learning is a subset of AI that focuses on the \"learning\" aspect. Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data; machine learning is a key tool in the data scientist\\'s toolkit.\\n\\nThis exploration will journey through the foundational concepts of machine learning, from its core typesâ€”supervised, unsupervised, and reinforcement learningâ€”to the intricate workflow of building an ML model. We will delve into the fascinating world of deep learning and neural networks, the engines behind today\\'s most advanced AI, and finally, we will examine the real-world applications, ethical challenges, and the exciting future that this transformative technology holds.\\n\\nThe Three Paradigms of Learning\\nMachine learning is broadly categorized into three main types, each defined by the nature of the data it uses and the problem it aims to solve.\\n\\n1. Supervised Learning: Learning with a Teacher\\nSupervised learning is the most common and straightforward type of machine learning. The core idea is to learn a mapping function that can predict an output variable (Y) based on input data (X). The defining characteristic is that the training data is labeled, meaning each data point is tagged with the correct output or \"ground truth.\"\\n\\nThink of it like a student learning with a teacher who provides a set of practice questions along with the correct answers. The student studies the questions and answers, learns the underlying patterns, and then uses that knowledge to answer new, unseen questions. In this analogy, the labeled training data is the question-and-answer key, and the ML model is the student.\\n\\nSupervised learning problems are further divided into two main categories:\\n\\nClassification: Predicting a Category\\nIn classification, the goal is to predict a discrete, categorical label. The output is a class, such as \"spam\" or \"not spam,\" \"cat\" or \"dog,\" or \"fraudulent\" or \"legitimate.\"\\n\\nHow it Works: The algorithm is trained on a dataset where each example belongs to a known class. It learns the decision boundary that separates the different classes. For example, an email spam filter learns the characteristics of spam (e.g., certain keywords, sender\\'s address patterns) and non-spam emails from a large, labeled dataset. When a new email arrives, the model applies what it learned to classify it.\\n\\nCommon Algorithms:\\n\\nLogistic Regression: Despite its name, it\\'s used for classification. It predicts the probability of an instance belonging to a certain class.\\n\\nK-Nearest Neighbors (KNN): A simple but effective algorithm that classifies a new data point based on the majority class of its \\'k\\' nearest neighbors in the feature space.\\n\\nSupport Vector Machines (SVM): Finds the optimal hyperplane that best separates the data points of different classes in a high-dimensional space.\\n\\nDecision Trees and Random Forests: Decision Trees create a tree-like model of decisions. Random Forests improve upon this by building an ensemble of many decision trees to produce a more robust and accurate prediction.\\n\\nUse Case: A bank uses a classification model to predict whether a credit card transaction is fraudulent based on features like transaction amount, location, time, and historical spending patterns.\\n\\nRegression: Predicting a Continuous Value\\nIn regression, the goal is to predict a continuous, numerical value. Instead of a category, the output is a quantity.\\n\\nHow it Works: The algorithm learns the relationship between the input features and the continuous output variable. The goal is to fit a line or curve to the data that minimizes the distance between the predicted values and the actual values.\\n\\nCommon Algorithms:\\n\\nLinear Regression: The simplest form, which models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data.\\n\\nPolynomial Regression: Extends linear regression by modeling the relationship as an nth-degree polynomial, allowing it to fit more complex, non-linear data.\\n\\nUse Case: A real estate company wants to predict house prices. The regression model would be trained on a dataset of houses with features like square footage, number of bedrooms, location, and age, along with their corresponding sale prices. The trained model could then predict the price of a new house on the market.\\n\\n2. Unsupervised Learning: Finding Patterns on Its Own\\nUnsupervised learning is used when the training data is unlabeled. The system is not told the \"right answer.\" Instead, the algorithm\\'s task is to explore the data and find some inherent structure or patterns within it on its own.\\n\\nThis is like a detective arriving at a chaotic crime scene with no initial suspects or theories. The detective must sift through the evidence, group related items, and identify patterns and connections to formulate a hypothesis about what happened. The algorithm acts as the detective, looking for the hidden structure in the raw data.\\n\\nUnsupervised learning is often used for exploratory data analysis and can be categorized as follows:\\n\\nClustering: Grouping Similar Data\\nClustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar to each other than to those in other clusters.\\n\\nHow it Works: The algorithm defines similarity based on the distance between data points in the feature space. It then iteratively groups points that are close together.\\n\\nCommon Algorithms:\\n\\nK-Means Clustering: An algorithm that aims to partition \\'n\\' observations into \\'k\\' clusters in which each observation belongs to the cluster with the nearest mean.\\n\\nHierarchical Clustering: Creates a tree of clusters (a dendrogram). It can be agglomerative (bottom-up) or divisive (top-down).\\n\\nUse Case: An e-commerce company uses clustering to perform customer segmentation. By clustering customers based on their purchasing behavior, browsing history, and demographics, the company can identify distinct groups (e.g., \"budget shoppers,\" \"brand loyalists,\" \"weekend browsers\") and tailor marketing strategies for each segment.\\n\\nAssociation: Discovering Rules\\nAssociation rule mining is a method for discovering interesting relationships between variables in large databases. The classic example is \"market basket analysis.\"\\n\\nHow it Works: The algorithm scours transaction data to find rules of the form \"If A, then B,\" meaning that items that appear together in a transaction are associated.\\n\\nUse Case: A supermarket analyzes its sales data and discovers the rule: {Diapers} -> {Beer}. This means that customers who buy diapers are also highly likely to buy beer. Armed with this insight, the store might place the beer aisle next to the diaper aisle to increase sales.\\n\\n3. Reinforcement Learning: Learning through Trial and Error\\nReinforcement Learning (RL) is a different beast altogether. It is concerned with how an intelligent agent ought to take actions in an environment in order to maximize some notion of cumulative reward.\\n\\nThe learning process is analogous to training a pet. You don\\'t give the pet an instruction manual on how to perform a trick. Instead, you reward it with a treat (positive reinforcement) when it performs the desired action correctly and perhaps withhold a treat (negative reinforcement) when it does not. Over time, the pet learns which actions lead to the best rewards.\\n\\nKey Concepts:\\n\\nAgent: The learner or decision-maker (e.g., the game-playing AI).\\n\\nEnvironment: The world in which the agent operates (e.g., the chessboard).\\n\\nAction: A move the agent can make (e.g., moving a pawn).\\n\\nState: The current situation of the environment.\\n\\nReward: The feedback from the environment for an action (e.g., +1 for winning, -1 for losing).\\n\\nPolicy: The strategy the agent uses to determine its next action based on the current state. The goal of RL is to find the optimal policy.\\n\\nHow it Works: The agent starts by taking random actions. It receives rewards or penalties based on these actions. Through millions of trial-and-error iterations, it gradually learns a policy that maximizes its long-term reward.\\n\\nUse Case: DeepMind\\'s AlphaGo was trained using reinforcement learning. It played millions of games against itself, gradually learning the strategies that led to winning. This allowed it to discover novel strategies and ultimately defeat the world\\'s best human Go players. RL is also crucial for robotics, supply chain optimization, and self-driving car navigation.\\n\\nThe Machine Learning Project Lifecycle\\nBuilding a successful machine learning model is not just about choosing an algorithm and feeding it data. It is a systematic, multi-step process that requires careful planning, execution, and iteration.\\n\\n1. Problem Definition & Scoping: The first and most critical step is to translate a business problem into a machine learning problem. What are we trying to predict? What is the desired outcome? What data is available? For example, a business problem of \"high customer churn\" is translated into an ML problem of \"predicting which customers are likely to churn in the next month.\"\\n\\n2. Data Collection: Data is the fuel for machine learning. It can be gathered from various sources, including internal databases (e.g., CRM systems), external APIs, publicly available datasets, or generated through surveys and experiments.\\n\\n3. Data Preprocessing and Cleaning: Real-world data is almost always messy. This phase, often the most time-consuming, involves preparing the data for the model.\\n\\nHandling Missing Values: Deciding whether to remove rows with missing data, or to impute (fill in) the missing values using statistical methods like the mean, median, or a more advanced model.\\n\\nCorrecting Errors: Identifying and fixing typos, inconsistent formatting (e.g., \"USA,\" \"U.S.A.,\" \"United States\"), and other inaccuracies.\\n\\nHandling Outliers: Detecting extreme values that could skew the model\\'s learning and deciding how to treat them.\\n\\nData Transformation: Normalizing or scaling numerical features so that they are on a comparable scale, which is crucial for many algorithms.\\n\\n4. Exploratory Data Analysis (EDA): Before building a model, it\\'s essential to understand the data. EDA involves using visualizations (histograms, scatter plots) and summary statistics to uncover patterns, identify anomalies, test hypotheses, and check assumptions. This step provides valuable insights that inform the subsequent stages.\\n\\n5. Feature Engineering: This is the art of creating new input features from the existing data to better represent the underlying problem to the model. For example, from a \"date of transaction\" feature, one could engineer new features like \"day of the week,\" \"month,\" or \"is_holiday,\" which might have more predictive power. Good feature engineering can be the difference between a mediocre model and a highly accurate one.\\n\\n6. Model Selection: Based on the problem (classification vs. regression), the size and nature of the data, and computational resources, a suitable algorithm or set of algorithms is chosen. It\\'s common practice to experiment with several different models.\\n\\n7. Model Training: This is where the learning happens. The preprocessed data is split into three sets:\\n\\nTraining Set (e.g., 70%): The largest portion, used to train the model. The model sees the input data and the corresponding labels and learns the mapping between them.\\n\\nValidation Set (e.g., 15%): Used to tune the model\\'s hyperparameters (the settings of the algorithm itself) and make decisions about the model\\'s architecture.\\n\\nTest Set (e.g., 15%): This data is held back and is completely unseen by the model during training and tuning. It is used only once, at the very end, to provide an unbiased evaluation of the final model\\'s performance on new data.\\n\\nDuring training, the model makes predictions, compares them to the true labels, calculates an \"error\" or \"loss,\" and adjusts its internal parameters to reduce this error in the next iteration. This process is repeated until the model\\'s performance on the validation set stops improving.\\n\\n8. Model Evaluation: After training, the model\\'s performance is assessed on the unseen test set using various metrics.\\n\\nFor Classification: Common metrics include Accuracy (overall correct predictions), Precision (of the positive predictions, how many were actually positive?), Recall (of all the actual positives, how many did we find?), and the F1-Score (the harmonic mean of precision and recall).\\n\\nFor Regression: Common metrics include Mean Squared Error (MSE) and R-squared, which measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\\n\\nA key challenge here is avoiding overfitting, where the model learns the training data too well, including its noise and random fluctuations, and fails to generalize to new data. The opposite problem is underfitting, where the model is too simple to capture the underlying structure of the data.\\n\\n9. Deployment and Monitoring: Once a satisfactory model is built, it is deployed into a production environment where it can make predictions on live data. The job isn\\'t over, however. The model\\'s performance must be continuously monitored because the real world changes. This phenomenon, known as model drift or concept drift, occurs when the statistical properties of the target variable change over time, causing the model to become less accurate. When drift is detected, the model may need to be retrained on new data.\\n\\nDeep Learning: The Brain-Inspired Powerhouse\\nWhile the machine learning techniques described so far are incredibly powerful, a specific subfield has driven the most significant breakthroughs in recent years: Deep Learning. Deep learning is based on Artificial Neural Networks (ANNs), which are computational models inspired by the structure and function of the human brain.\\n\\nThe Artificial Neuron\\nThe basic building block of a neural network is the artificial neuron, or perceptron. A neuron receives one or more inputs, performs a simple computation, and produces an output. Each input is assigned a weight, which signifies its importance. The neuron sums up all the weighted inputs, adds a bias term, and then passes this result through an activation function. The activation function introduces non-linearity, allowing the network to learn complex patterns that a simple linear model cannot.\\n\\nFrom a Single Neuron to a Deep Network\\nA single neuron can only make simple decisions. The real power comes from organizing these neurons into layers. A typical neural network has:\\n\\nAn Input Layer: Receives the raw data (e.g., the pixels of an image).\\n\\nOne or more Hidden Layers: The computational engine of the network. This is where the feature extraction and transformation happen. A \"deep\" neural network is one with many hidden layers.\\n\\nAn Output Layer: Produces the final prediction (e.g., the probability of the image being a \"cat\").\\n\\nWhen data is fed into the network (forward propagation), the neurons in each layer process the outputs from the previous layer and pass them on to the next. The final output is a prediction. This prediction is compared to the true label, and an error is calculated. This error is then propagated backward through the network (backpropagation). During backpropagation, the network uses an optimization algorithm like Gradient Descent to slightly adjust the weights and biases of every neuron in a way that minimizes the error. This cycle of forward and backward propagation is repeated thousands or millions of times with the training data, allowing the network to \"learn.\"\\n\\nThe magic of deep learning is that the hidden layers learn to detect features in a hierarchical manner. In an image recognition task, the first hidden layer might learn to detect simple edges and colors. The next layer might combine these to detect shapes like eyes and noses. A subsequent layer might combine those to detect faces, and so on, until the final layer can classify the entire image.\\n\\nKey Deep Learning Architectures\\nDifferent problems require different network architectures. Three of the most influential are:\\n\\nConvolutional Neural Networks (CNNs): The go-to architecture for computer vision tasks. CNNs use special layers called convolutional and pooling layers that are designed to process grid-like data, such as images. They are incredibly effective at recognizing patterns, objects, and faces in visual data. They power everything from facial recognition on your phone to the vision systems in self-driving cars.\\n\\nRecurrent Neural Networks (RNNs): Designed to work with sequential data, where the order of information matters, such as text or time-series data. RNNs have a form of \"memory\" that allows information to persist from one step in the sequence to the next. This makes them suitable for tasks like machine translation, speech recognition, and sentiment analysis. Variants like Long Short-Term Memory (LSTM) networks were developed to overcome some of the limitations of basic RNNs, allowing them to learn long-range dependencies.\\n\\nTransformers: A revolutionary architecture, introduced in 2017, that has taken the field of Natural Language Processing (NLP) by storm. Transformers use a mechanism called self-attention to weigh the importance of different words in the input text, allowing them to process entire sequences at once and capture complex contextual relationships. This architecture is the foundation for state-of-the-art Large Language Models (LLMs) like GPT (Generative Pre-trained Transformer) and BERT.\\n\\nThe World Transformed: Applications, Challenges, and the Future\\nMachine learning is no longer a niche academic field; it is a general-purpose technology that is reshaping industries and daily life.\\n\\nReal-World Applications\\nHealthcare: ML models analyze medical images (X-rays, MRIs) to detect tumors and other anomalies, often with accuracy rivaling human radiologists. They also help in discovering new drugs, personalizing treatment plans, and predicting disease outbreaks.\\n\\nFinance: Algorithms are used for high-frequency trading, credit scoring, loan approval, and detecting fraudulent transactions in real-time.\\n\\nRetail and E-commerce: Recommendation engines, like those used by Amazon and Netflix, are powered by ML. They analyze your past behavior to suggest products or movies you might like. ML also optimizes supply chains and forecasts demand.\\n\\nTransportation: Self-driving cars use a complex suite of ML models for perception, prediction, and planning to navigate the world safely. Ride-sharing apps use ML to predict demand, set prices (surge pricing), and optimize routes.\\n\\nEntertainment: Streaming services use ML to recommend content, while music apps create personalized playlists. It\\'s even being used to generate music and art.\\n\\nChallenges and Ethical Considerations\\nDespite its immense potential, the widespread adoption of machine learning raises significant challenges:\\n\\nData Bias: An ML model is only as good as the data it\\'s trained on. If the training data reflects existing societal biases (e.g., historical hiring data that favors one gender), the model will learn and perpetuate, or even amplify, those biases. This can lead to unfair or discriminatory outcomes.\\n\\nThe Black Box Problem: Many advanced models, especially deep neural networks, are \"black boxes.\" We know they work, but it can be extremely difficult to understand why they made a specific decision. This lack of interpretability is a major problem in high-stakes domains like healthcare and criminal justice.\\n\\nPrivacy and Security: ML models often require vast amounts of data, some of which may be sensitive and personal. This raises significant privacy concerns. Furthermore, models are vulnerable to adversarial attacks, where malicious actors can fool a model with carefully crafted, imperceptible changes to the input data.\\n\\nComputational Cost: Training large-scale models, particularly in deep learning, is incredibly expensive, requiring massive amounts of data and specialized hardware, which consumes a great deal of energy.\\n\\nThe Future is Learning\\nThe field of machine learning is evolving at a breathtaking pace. Looking ahead, several trends are set to define its next chapter:\\n\\nGenerative AI: Models that can create new, original content, from realistic images and human-like text to music and code. This technology is poised to revolutionize creative industries and scientific research.\\n\\nAutoML (Automated Machine Learning): The process of automating the end-to-end process of applying machine learning to real-world problems. AutoML aims to make ML more accessible to non-experts.\\n\\nFederated Learning: A privacy-preserving technique where a model is trained across multiple decentralized devices (like mobile phones) holding local data samples, without exchanging the data itself.\\n\\nAI for Science: ML is becoming an indispensable tool for scientific discovery, accelerating research in fields from genomics and materials science to climate modeling and astrophysics.\\n\\nIn conclusion, machine learning represents a fundamental shift in how we solve problems and build intelligent systems. It is a tool of unprecedented power, enabling us to find patterns in complexity, make predictions from data, and automate tasks once thought to be the exclusive domain of human intellect. As we continue to navigate this new era, the key will be to harness its power responsibly, ensuring that the dawn of this new intelligence benefits all of humanity.', 'number': 5, 'subject': 'Machine Learning', 'tone': 'Simple', 'response_json': '{\"1\": {\"mcq\": \"multiple choice qustion\", \"options\": {\"a\": \"option 1\", \"b\": \"option 2\", \"c\": \"option 3\", \"d\": \"option 4\"}, \"answer\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice qustion\", \"options\": {\"a\": \"option 1\", \"b\": \"option 2\", \"c\": \"option 3\", \"d\": \"option 4\"}, \"answer\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice qustion\", \"options\": {\"a\": \"option 1\", \"b\": \"option 2\", \"c\": \"option 3\", \"d\": \"option 4\"}, \"answer\": \"correct answer\"}}', 'quiz': '```json\\n[\\n  {\\n    \"question\": \"According to the text, what is Artificial Intelligence (AI)?\",\\n    \"options\": [\\n      \"Intelligence displayed by animals\",\\n      \"Natural intelligence displayed by humans\",\\n      \"Intelligence demonstrated by machines\",\\n      \"The study of intelligent agents\"\\n    ],\\n    \"answer\": \"Intelligence demonstrated by machines\",\\n    \"explanation\": \"The text explicitly states, \\'Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans.\\'\"\\n  },\\n  {\\n    \"question\": \"How do leading AI textbooks define the field of AI?\",\\n    \"options\": [\\n      \"As the study of human intelligence\",\\n      \"As the study of natural intelligence\",\\n      \"As the study of \\'intelligent agents\\'\",\\n      \"As the study of advanced web search engines\"\\n    ],\\n    \"answer\": \"As the study of \\'intelligent agents\\'\",\\n    \"explanation\": \"The text mentions, \\'Leading AI textbooks define the field as the study of \\'intelligent agents\\': any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\\'\"\\n  },\\n  {\\n    \"question\": \"Which of the following is NOT mentioned as an application of AI in the provided text?\",\\n    \"options\": [\\n      \"Advanced web search engines\",\\n      \"Recommendation systems\",\\n      \"Developing new programming languages\",\\n      \"Self-driving cars\"\\n    ],\\n    \"answer\": \"Developing new programming languages\",\\n    \"explanation\": \"The text lists various applications like advanced web search engines, recommendation systems, understanding human speech, self-driving cars, generative AI, and competing in strategic game systems, but it does not mention \\'developing new programming languages\\'.\"\\n  }\\n]\\n```', 'review': 'To properly evaluate the quiz, I need two crucial pieces of information that are currently placeholders:\\n\\n1.  **`{subject}`**: Please specify the subject area of the quiz (e.g., English Literature, Biology, History, Mathematics, etc.).\\n2.  **`sy=tudents`**: Please clarify the specific student level or grade (e.g., 5th graders, high school sophomores, university freshmen, etc.).\\n3.  **`{quiz}`**: Please provide the actual quiz content in JSON format.\\n\\nOnce you provide these details, I will be able to perform a thorough evaluation as requested.'}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "616065f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_data(quiz_str):\n",
    "    try:\n",
    "        # Clean the string from markdown formatting\n",
    "        cleaned_str = quiz_str.strip().lstrip(\"```json\").rstrip(\"```\").strip()\n",
    "        \n",
    "        # This variable will be a list of dictionaries\n",
    "        quiz_list = json.loads(cleaned_str) \n",
    "        quiz_table_data = []\n",
    "\n",
    "        # Iterate directly over the list\n",
    "        for item in quiz_list:\n",
    "            mcq = item.get(\"question\")\n",
    "            options = \" || \".join(item.get(\"options\", []))\n",
    "            answer = item.get(\"answer\")\n",
    "            \n",
    "            quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Answer\": answer})\n",
    "\n",
    "        return quiz_table_data\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "309f7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens Used: 3169\n",
      "Prompt Tokens: 265\n",
      "Completion Tokens: 516\n",
      "Total Cost (USD): $0.0000\n",
      "[{'MCQ': 'According to the text, what is Artificial Intelligence (AI)?', 'Choices': 'Intelligence displayed by animals || Natural intelligence displayed by humans || Intelligence demonstrated by machines || The study of intelligent agents', 'Answer': 'Intelligence demonstrated by machines'}, {'MCQ': 'How do leading AI textbooks define the field of AI?', 'Choices': \"As the study of human intelligence || As the study of natural intelligence || As the study of 'intelligent agents' || As the study of advanced web search engines\", 'Answer': \"As the study of 'intelligent agents'\"}, {'MCQ': 'Which of the following is NOT mentioned as an application of AI in the provided text?', 'Choices': 'Advanced web search engines || Recommendation systems || Developing new programming languages || Self-driving cars', 'Answer': 'Developing new programming languages'}]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens Used: {cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "print(f\"Total Cost (USD): ${cb.total_cost:.4f}\")\n",
    "if isinstance(response,dict):\n",
    "                quiz = response.get(\"quiz\",None)    \n",
    "                if quiz is not None:\n",
    "                    table_data = get_table_data(quiz)\n",
    "                    print(table_data)\n",
    "                    if table_data is not None:\n",
    "                        df = pd.DataFrame(table_data)\n",
    "                        df.index += 1\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90a468e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 MCQ  \\\n",
      "1  According to the text, what is Artificial Inte...   \n",
      "2  How do leading AI textbooks define the field o...   \n",
      "3  Which of the following is NOT mentioned as an ...   \n",
      "\n",
      "                                             Choices  \\\n",
      "1  Intelligence displayed by animals || Natural i...   \n",
      "2  As the study of human intelligence || As the s...   \n",
      "3  Advanced web search engines || Recommendation ...   \n",
      "\n",
      "                                  Answer  \n",
      "1  Intelligence demonstrated by machines  \n",
      "2   As the study of 'intelligent agents'  \n",
      "3   Developing new programming languages  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ce00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
