{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8774b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab79707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing api key\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    google_api_key=os.getenv(\"GOOGLE-API-KEY\"),\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Say hello in Python\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ababefa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    google_api_key = os.getenv(\"GOOGLE-API-KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb11ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain,SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4501df",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text your job is to create {number} multiple choice questions in {tone} tone.\n",
    "Make sure questions are not repeated and make sure that they follow the text above.\n",
    "Make sure to format the response on basis of RESPONSE_JSON below.\n",
    "##RESPONSE_JSON\n",
    "{response_json} \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\":{\n",
    "        \"mcq\":\"multiple choice qustion\",\n",
    "        \"options\":{\n",
    "            \"a\":\"option 1\",\n",
    "            \"b\":\"option 2\",\n",
    "            \"c\":\"option 3\",\n",
    "            \"d\":\"option 4\"\n",
    "        },\n",
    "        \"answer\":\"correct answer\",\n",
    "    },\n",
    "    \"2\":{\n",
    "        \"mcq\":\"multiple choice qustion\",\n",
    "        \"options\":{\n",
    "            \"a\":\"option 1\",\n",
    "            \"b\":\"option 2\",\n",
    "            \"c\":\"option 3\",\n",
    "            \"d\":\"option 4\"\n",
    "        },\n",
    "        \"answer\":\"correct answer\",\n",
    "    },\n",
    "    \"3\":{\n",
    "        \"mcq\":\"multiple choice qustion\",\n",
    "        \"options\":{\n",
    "            \"a\":\"option 1\",\n",
    "            \"b\":\"option 2\",\n",
    "            \"c\":\"option 3\",\n",
    "            \"d\":\"option 4\"\n",
    "        },\n",
    "        \"answer\":\"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "quiz_chain = RunnableParallel({\n",
    "    \"quiz\": quiz_generation_prompt | llm,\n",
    "    \"subject\": RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "Youo are an expert english grammarian and writer. Given a multiple choice Quiz for {subject} students.\n",
    "You need to evaluate the complexity of the quiz questions, and also check wheather is quiz is adapt to the quantitstive and cognitive ability of students.\n",
    "If not yiu need to change the questions and change the tone so that it perfectly fits the students abilities.\n",
    "QUIZ MCQ:{quiz}\n",
    "\n",
    "Check as an expert english Writer for the above quiz.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=['subject','quiz'],\n",
    "    template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ce78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = RunnableSequence(\n",
    "    quiz_evaluation_prompt,\n",
    "    llm,\n",
    "    RunnableLambda(lambda x: {\"review\": x})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "generate_evaluate_chain = quiz_chain | review_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"P:\\Code\\Gen_AI_course_ineuron\\MCQ_GEN_AI\\data.txt\"\n",
    "with open(file_path,\"r\") as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d43055",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7eaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 5\n",
    "SUBJECT = \"python\"\n",
    "TONE = \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def get_gemini_callback():\n",
    "    usage_log = {\n",
    "        \"prompt_tokens\": 0,\n",
    "        \"completion_tokens\": 0,\n",
    "        \"total_tokens\": 0,\n",
    "        \"total_cost\": 0.0\n",
    "    }\n",
    "    yield usage_log\n",
    "    # You can log or return this after yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_output = quiz_chain.invoke(\n",
    "    {\n",
    "        \"text\": TEXT,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_gemini_callback() as gc:\n",
    "    response = generate_evaluate_chain.invoke(\n",
    "        {\n",
    "            \"text\":TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6643ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = quiz_output.get(\"quiz\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_string = res.content\n",
    "cleaned_string = quiz_string.strip(\"```json\\n\").strip(\"`\")\n",
    "final_mcqs = json.loads(cleaned_string)\n",
    "final_mcqs\n",
    "print(json.dumps(final_mcqs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key,value in final_mcqs.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    answer = value[\"answer\"]\n",
    "    quiz_table_data.append({\"MCQ\":mcq,\"Choices\":options,\"Answer\":answer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad25abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"machinelearning.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f09cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from src.mcqgenerator.utils import read_file,get_table_data\n",
    "from src.mcqgenerator.looger import logging\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    google_api_key = os.getenv(\"GOOGLE-API-KEY\"),\n",
    "    temperature = 0.7,\n",
    ")\n",
    "\n",
    "quiz_generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"You are an expert MCQ quiz maker. You have to create the quiz based on user input and given instructions.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content = \"\"\"\n",
    "                Please create {number} muliple choice questions in a {tone} tone based on the following text.\n",
    "                **Text:**\n",
    "                {text}\n",
    "                \n",
    "                **Instructions:**\n",
    "                1. Ensure that all questions are from given text only.\n",
    "                2. Ensure that the questions are not repeated.\n",
    "                3. Format your entire response as a JSON object that strictly follows below given scheme.\n",
    "                {response_json}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]    \n",
    ")\n",
    "\n",
    "quiz_chain = LLMChain(llm=llm,prompt = quiz_generation_prompt, ouput_key=\"quiz\",verbose=True)\n",
    "\n",
    "res = quiz_chain.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import __all__\n",
    "print(__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import __all__\n",
    "print(__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from src.mcqgenerator.utils import read_file,get_table_data\n",
    "from src.mcqgenerator.MCQGenerator import genereate_evaluate_chain\n",
    "from src.mcqgenerator.looger import logging\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "with open('Response.json','r') as file:\n",
    "    RESPONSE_JSON = json.load(file)\n",
    "\n",
    "st.title(\"MCQ generator using LangChain\")\n",
    "\n",
    "with st.form(\"user_inputs\"):\n",
    "    uploaded_file = st.file_uploader(\"Upload a PDF or TEXT file\")\n",
    "    mcq_count = st.number_input(\"No. of MCQ\",min_value=3,max_value=50)\n",
    "    subject = st.text_input(\"Enter subject\",max_chars=20)\n",
    "    tone = st.text_input(\"Complexity level of Questions\",max_chars=20,placeholder=\"Simple\")\n",
    "    button = st.form_submit_button(\"Create MCQ\")\n",
    "\n",
    "\n",
    "if button and uploaded_file is not None and mcq_count and subject and tone:\n",
    "    with st.spinner(\"Loading....\"):\n",
    "        try:\n",
    "            text = read_file(uploaded_file)\n",
    "            with get_openai_callback() as cb:\n",
    "                response = genereate_evaluate_chain.invoke(\n",
    "                    {\n",
    "                        \"text\": text,\n",
    "                        \"number\":mcq_count,\n",
    "                        \"subject\": subject,\n",
    "                        \"tone\":tone,\n",
    "                        \"response_json\": RESPONSE_JSON\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            traceback.print_exception(type(e),e,e.__traceback__)\n",
    "            st.error(\"Error\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Total Tokens Used: {cb.total_tokens}\")\n",
    "            print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "            print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "            print(f\"Total Cost (USD): ${cb.total_cost:.4f}\")\n",
    "            if isinstance(response,dict):\n",
    "                quiz = response.get(\"quiz\",None)    \n",
    "                if quiz is not None:\n",
    "                    table_data = get_table_data(quiz)\n",
    "                    if table_data is not None:\n",
    "                        df = pd.DataFrame(table_data)\n",
    "                        df.index += 1\n",
    "                        st.table(df)\n",
    "                        st.text_area(label=\"Review\",value=response[\"review\"])\n",
    "                    else:\n",
    "                        st.error(\"Error in the table data\")\n",
    "            else:\n",
    "                st.write(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932dd14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
